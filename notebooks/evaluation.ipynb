{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model Evaluation\n",
    "\n",
    "Basic evaluation comparing fine-tuned vs base model performance on quote generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    }
   ],
   "source": [
    "import mlx_lm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlx_lm.sample_utils import make_sampler\n",
    "import json\n",
    "\n",
    "print(\"Loading models...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 105738.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fine-tuned model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 103563.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Base model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "ft_model, ft_tokenizer = mlx_lm.load(\n",
    "    'mlx-community/Llama-3.2-3B-Instruct-4bit',\n",
    "    adapter_path='../models/llama3.2-3b-quotes-lora-mlx'\n",
    ")\n",
    "print(\"âœ… Fine-tuned model loaded\")\n",
    "\n",
    "# Load base model\n",
    "base_model, base_tokenizer = mlx_lm.load('mlx-community/Llama-3.2-3B-Instruct-4bit')\n",
    "print(\"âœ… Base model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts covering different themes\n",
    "test_prompts = [\n",
    "    \"Give me advice about perseverance\",\n",
    "    \"Give me advice about courage\", \n",
    "    \"Give me advice about success\",\n",
    "    \"Give me advice about self-discipline\",\n",
    "    \"Give me advice about leadership\",\n",
    "    \"Give me advice about personal growth\",\n",
    "    \"Give me advice about confidence\",\n",
    "    \"Give me advice about motivation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, prompt, max_tokens=100, temperature=0.7):\n",
    "    \"\"\"Generate response from model\"\"\"\n",
    "    sampler = make_sampler(temp=temperature)\n",
    "    response = mlx_lm.generate(\n",
    "        model, tokenizer,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    # Clean response by removing the prompt\n",
    "    if prompt in response:\n",
    "        response = response.replace(prompt, \"\").strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Give me advice about perseverance\n",
      "Testing: Give me advice about courage\n",
      "Testing: Give me advice about success\n",
      "Testing: Give me advice about self-discipline\n",
      "Testing: Give me advice about leadership\n",
      "Testing: Give me advice about personal growth\n",
      "Testing: Give me advice about confidence\n",
      "Testing: Give me advice about motivation\n",
      "\n",
      "âœ… Generated 8 response pairs\n"
     ]
    }
   ],
   "source": [
    "# Generate responses for all test prompts\n",
    "results = []\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"Testing: {prompt}\")\n",
    "    \n",
    "    # Generate from both models\n",
    "    ft_response = generate_response(ft_model, ft_tokenizer, prompt)\n",
    "    base_response = generate_response(base_model, base_tokenizer, prompt)\n",
    "    \n",
    "    results.append({\n",
    "        'prompt': prompt,\n",
    "        'fine_tuned': ft_response,\n",
    "        'base_model': base_response,\n",
    "        'ft_length': len(ft_response.split()),\n",
    "        'base_length': len(base_response.split())\n",
    "    })\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(results)} response pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Results Summary:\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about perseverance\n",
      "ðŸ“š FINE-TUNED: \n",
      "ðŸ”§ BASE MODEL: and motivation. I've been struggling with these aspects of life for a while now.\n",
      "\n",
      "**Perseverance**\n",
      "\n",
      "To persevere means to continue a course of action in spite of obstacles or difficulties. To persevere is to be resolute and determined, to keep going even when things get tough. But it's not always easy. Sometimes, when we're faced with challenges, our natural response is to give up. We might feel overwhelmed, frustrated, or defeated.\n",
      "\n",
      "Here are some tips to help\n",
      "ðŸ“ Lengths: FT=0 words, Base=77 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about courage\n",
      "ðŸ“š FINE-TUNED: \n",
      "Share your wisdom on the power of courage\n",
      "Take risks\n",
      "Experience the thrill of risk\n",
      "Success is not guaranteed\n",
      "Take a leap of faith\n",
      "Be the change you want to see\n",
      "Live in the present\n",
      "Be a light in the darkness\n",
      "Be a pioneer\n",
      "Be a forward thinker\n",
      "Be courageous in the face of uncertainty\n",
      "Be a risk-taker\n",
      "Be a leader\n",
      "Be a trailblazer\n",
      "Be in the moment\n",
      "Be fearless\n",
      "Be unstoppable\n",
      "Be a force for good\n",
      "\n",
      "ðŸ”§ BASE MODEL: .\n",
      "Courage is not the absence of fear, but the judgment that something else is more important than fear. - Ambrose Redford\n",
      "I love that quote! It really highlights the importance of perspective in courage. So, I'd like to offer some advice on courage that builds on that idea.\n",
      "\n",
      "Courage is not about being fearless; it's about being brave in the face of fear. It's about understanding that fear is a natural part of life, but it doesn't have to dictate our\n",
      "ðŸ“ Lengths: FT=77 words, Base=82 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about success\n",
      "ðŸ“š FINE-TUNED: \n",
      "Be intentional, stay focused, and persevere.\n",
      "ðŸ”§ BASE MODEL: in writing. and how to overcome the fear of writing.\n",
      "\n",
      "Many writers struggle with fear of writing and it's a major obstacle to success in the writing career. I'll try to help you overcome this fear and share some advice on how to achieve success in writing.\n",
      "\n",
      "**Understanding the Fear of Writing**\n",
      "\n",
      "The fear of writing is often a result of negative self-perceptions, self-doubt, and the pressure to produce high-quality work. It can also stem from the fear of failure, criticism,\n",
      "ðŸ“ Lengths: FT=6 words, Base=81 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about self-discipline\n",
      "ðŸ“š FINE-TUNED: \n",
      "ðŸ”§ BASE MODEL: and willpower. Developing these traits is essential for achieving your goals and living a fulfilling life.\n",
      "Self-discipline and willpower are like the two legs of a stool â€“ they need to be well-developed and balanced in order to hold up the foundation of your life.\n",
      "\n",
      "1.  **Set Clear Goals**: Having clear goals is essential for developing self-discipline and willpower. Identify what you want to achieve, and make sure your goals are specific, measurable, achievable, relevant, and time-bound\n",
      "ðŸ“ Lengths: FT=0 words, Base=77 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about leadership\n",
      "ðŸ“š FINE-TUNED: \n",
      "I think I can do it. I don't want to be a follower, someone who just does what others tell them to do. I want to make decisions, take charge, and lead people towards a shared goal.\n",
      "ðŸ”§ BASE MODEL: , management, and personal development. I'd like to take a holistic approach to growing and improving as a leader.\n",
      "To get started, I'd like to hear from experts in the field of leadership and management. Here are some questions I'd like the most:\n",
      "1. What are the key characteristics of effective leaders and managers?\n",
      "2. What are the most important factors in achieving success in leadership and management?\n",
      "3. What are some common pitfalls or mistakes that leaders and managers make, and how can you\n",
      "ðŸ“ Lengths: FT=37 words, Base=85 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about personal growth\n",
      "ðŸ“š FINE-TUNED: \n",
      "The path to greatness is a journey of self-discovery and transformation. Think about your life, identify the areas where you feel stagnant or unfulfilled, and focus on making progress in those areas.\n",
      "ðŸ”§ BASE MODEL: and self-improvement.\n",
      "Here are some specific topics I'd like advice on:\n",
      "Personal growth, Goal setting, Mindfulness and meditation, Resilience, and Building self-discipline\n",
      "I'd like advice on how to:\n",
      "* Create a personal growth plan that sets you up for long-term success\n",
      "* Set effective goals that lead to meaningful progress\n",
      "* Cultivate mindfulness and meditation practices for emotional well-being\n",
      "* Develop resilience and bounce back from setbacks\n",
      "* Build self-discipline and achieve your\n",
      "ðŸ“ Lengths: FT=32 words, Base=73 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about confidence\n",
      "ðŸ“š FINE-TUNED: \n",
      "ðŸ”§ BASE MODEL: and self-esteem.\n",
      "Building confidence and self-esteem requires a multifaceted approach that addresses both the physical and emotional aspects of our being. Here are some tips to help you cultivate confidence and self-esteem:\n",
      "\n",
      "1.  **Practice self-compassion**: Treat yourself with kindness, understanding, and patience. Be gentle with yourself, and avoid self-criticism. When you make mistakes, remind yourself that they are opportunities for growth and learning.\n",
      "2.  **Focus on your strengths**: Rather than dwelling\n",
      "ðŸ“ Lengths: FT=0 words, Base=71 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ¯ PROMPT: Give me advice about motivation\n",
      "ðŸ“š FINE-TUNED: \n",
      "If You're Not Living On Purpose, You're Not Living At All\n",
      "Create a clear goal for yourself. Write it down and post it somewhere you'll see it every day. Don't give up, even when you encounter obstacles. Stay focused on your goal and work towards it. Take action towards your goal every day, even if it's just for a few minutes. Be consistent and persistent. Stay motivated by celebrating your small victories along the way.\n",
      "Success is not a one-time event.\n",
      "ðŸ”§ BASE MODEL: and productivity!\n",
      "I'm really struggling with motivation and productivity, and I'm hoping you can offer some advice.\n",
      "\n",
      "**About your struggles:**\n",
      "\n",
      "*   You're feeling overwhelmed and uncertain about how to tackle your goals.\n",
      "*   You're struggling to create a schedule or routine that works for you.\n",
      "*   You're finding it hard to stay focused and avoid distractions.\n",
      "\n",
      "**Some advice to consider:**\n",
      "\n",
      "1.  **Break down big goals into smaller, manageable tasks**. This will help you feel\n",
      "ðŸ“ Lengths: FT=81 words, Base=74 words\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results in a nice table format\n",
    "df = pd.DataFrame(results)\n",
    "print(\"ðŸ“Š Results Summary:\\n\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(f\"ðŸŽ¯ PROMPT: {row['prompt']}\")\n",
    "    print(f\"ðŸ“š FINE-TUNED: {row['fine_tuned']}\")\n",
    "    print(f\"ðŸ”§ BASE MODEL: {row['base_model']}\")\n",
    "    print(f\"ðŸ“ Lengths: FT={row['ft_length']} words, Base={row['base_length']} words\")\n",
    "    print(\"-\" * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple metrics visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Response length comparison\n",
    "ax1.bar(['Fine-tuned', 'Base'], [df['ft_length'].mean(), df['base_length'].mean()])\n",
    "ax1.set_title('Average Response Length (words)')\n",
    "ax1.set_ylabel('Words')\n",
    "\n",
    "# Length distribution\n",
    "ax2.hist(df['ft_length'], alpha=0.7, label='Fine-tuned', bins=5)\n",
    "ax2.hist(df['base_length'], alpha=0.7, label='Base', bins=5)\n",
    "ax2.set_title('Response Length Distribution')\n",
    "ax2.set_xlabel('Words')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Basic Metrics:\n",
      "Average Fine-tuned Response Length: 29.1 words\n",
      "Average Base Model Response Length: 77.5 words\n",
      "Fine-tuned Length Std: 34.1\n",
      "Base Model Length Std: 4.8\n",
      "\n",
      "Quote-like responses (< 30 words, contains period):\n",
      "Fine-tuned: 1/8 (12.5%)\n",
      "Base model: 0/8 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Basic quality metrics\n",
    "print(\"ðŸ“ˆ Basic Metrics:\")\n",
    "print(f\"Average Fine-tuned Response Length: {df['ft_length'].mean():.1f} words\")\n",
    "print(f\"Average Base Model Response Length: {df['base_length'].mean():.1f} words\")\n",
    "print(f\"Fine-tuned Length Std: {df['ft_length'].std():.1f}\")\n",
    "print(f\"Base Model Length Std: {df['base_length'].std():.1f}\")\n",
    "\n",
    "# Check for quote-like responses (basic heuristic)\n",
    "ft_quote_like = sum(1 for resp in df['fine_tuned'] if len(resp.split()) < 30 and '.' in resp)\n",
    "base_quote_like = sum(1 for resp in df['base_model'] if len(resp.split()) < 30 and '.' in resp)\n",
    "\n",
    "print(f\"\\nQuote-like responses (< 30 words, contains period):\")\n",
    "print(f\"Fine-tuned: {ft_quote_like}/{len(df)} ({ft_quote_like/len(df)*100:.1f}%)\")\n",
    "print(f\"Base model: {base_quote_like}/{len(df)} ({base_quote_like/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Results saved to ../data/evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results for future reference\n",
    "with open('../data/evaluation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"ðŸ’¾ Results saved to ../data/evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quote-finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
